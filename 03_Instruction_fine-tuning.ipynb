{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10876fe7-b16e-4dda-8e8f-d699b37a56fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21683805-a3a9-43db-8233-26c156e2f26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "222f5dd9-21a9-4c25-aa37-8f76b1cba867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llama can't be installed directly, \n",
    "#so run: pip install lamini, which will install llama package then run the following code\n",
    "\n",
    "from llama import BasicModelRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1265152c-d78b-4b57-9244-668a046c8107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77142fae-312b-41a9-aa8a-150fb84a6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_tuned_dataset = load_dataset(\"tatsu-lab/alpaca\", split=\"train\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee807286-4c11-4a84-97ed-5057536875c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction tuned dataset...\n",
      "{'input': '',\n",
      " 'instruction': 'Give three tips for staying healthy.',\n",
      " 'output': '1.Eat a balanced diet and make sure to include plenty of fruits '\n",
      "           'and vegetables. \\n'\n",
      "           '2. Exercise regularly to keep your body active and strong. \\n'\n",
      "           '3. Get enough sleep and maintain a consistent sleep schedule.',\n",
      " 'text': 'Below is an instruction that describes a task. Write a response that '\n",
      "         'appropriately completes the request.\\n'\n",
      "         '\\n'\n",
      "         '### Instruction:\\n'\n",
      "         'Give three tips for staying healthy.\\n'\n",
      "         '\\n'\n",
      "         '### Response:\\n'\n",
      "         '1.Eat a balanced diet and make sure to include plenty of fruits and '\n",
      "         'vegetables. \\n'\n",
      "         '2. Exercise regularly to keep your body active and strong. \\n'\n",
      "         '3. Get enough sleep and maintain a consistent sleep schedule.'}\n",
      "{'input': '',\n",
      " 'instruction': 'What are the three primary colors?',\n",
      " 'output': 'The three primary colors are red, blue, and yellow.',\n",
      " 'text': 'Below is an instruction that describes a task. Write a response that '\n",
      "         'appropriately completes the request.\\n'\n",
      "         '\\n'\n",
      "         '### Instruction:\\n'\n",
      "         'What are the three primary colors?\\n'\n",
      "         '\\n'\n",
      "         '### Response:\\n'\n",
      "         'The three primary colors are red, blue, and yellow.'}\n",
      "{'input': '',\n",
      " 'instruction': 'Describe the structure of an atom.',\n",
      " 'output': 'An atom is made up of a nucleus, which contains protons and '\n",
      "           'neutrons, surrounded by electrons that travel in orbits around the '\n",
      "           'nucleus. The protons and neutrons have a positive charge, while '\n",
      "           'the electrons have a negative charge, resulting in an overall '\n",
      "           'neutral atom. The number of each particle determines the atomic '\n",
      "           'number and the type of atom.',\n",
      " 'text': 'Below is an instruction that describes a task. Write a response that '\n",
      "         'appropriately completes the request.\\n'\n",
      "         '\\n'\n",
      "         '### Instruction:\\n'\n",
      "         'Describe the structure of an atom.\\n'\n",
      "         '\\n'\n",
      "         '### Response:\\n'\n",
      "         'An atom is made up of a nucleus, which contains protons and '\n",
      "         'neutrons, surrounded by electrons that travel in orbits around the '\n",
      "         'nucleus. The protons and neutrons have a positive charge, while the '\n",
      "         'electrons have a negative charge, resulting in an overall neutral '\n",
      "         'atom. The number of each particle determines the atomic number and '\n",
      "         'the type of atom.'}\n",
      "{'input': '',\n",
      " 'instruction': 'How can we reduce air pollution?',\n",
      " 'output': 'There are a number of ways to reduce air pollution, such as '\n",
      "           'shifting to renewable energy sources, encouraging the use of '\n",
      "           'public transportation, prohibiting the burning of fossil fuels, '\n",
      "           'implementing policies to reduce emissions from industrial sources, '\n",
      "           'and implementing vehicle emissions standards. Additionally, '\n",
      "           'individuals can do their part to reduce air pollution by reducing '\n",
      "           'car use, avoiding burning materials such as wood, and changing to '\n",
      "           'energy efficient appliances.',\n",
      " 'text': 'Below is an instruction that describes a task. Write a response that '\n",
      "         'appropriately completes the request.\\n'\n",
      "         '\\n'\n",
      "         '### Instruction:\\n'\n",
      "         'How can we reduce air pollution?\\n'\n",
      "         '\\n'\n",
      "         '### Response:\\n'\n",
      "         'There are a number of ways to reduce air pollution, such as shifting '\n",
      "         'to renewable energy sources, encouraging the use of public '\n",
      "         'transportation, prohibiting the burning of fossil fuels, '\n",
      "         'implementing policies to reduce emissions from industrial sources, '\n",
      "         'and implementing vehicle emissions standards. Additionally, '\n",
      "         'individuals can do their part to reduce air pollution by reducing '\n",
      "         'car use, avoiding burning materials such as wood, and changing to '\n",
      "         'energy efficient appliances.'}\n",
      "{'input': '',\n",
      " 'instruction': 'Describe a time when you had to make a difficult decision.',\n",
      " 'output': 'I had to make a difficult decision when I was working as a project '\n",
      "           'manager at a construction company. I was in charge of a project '\n",
      "           'that needed to be completed by a certain date in order to meet the '\n",
      "           'client’s expectations. However, due to unexpected delays, we were '\n",
      "           'not able to meet the deadline and so I had to make a difficult '\n",
      "           'decision. I decided to extend the deadline, but I had to stretch '\n",
      "           'the team’s resources even further and increase the budget. '\n",
      "           'Although it was a risky decision, I ultimately decided to go ahead '\n",
      "           'with it to ensure that the project was completed on time and that '\n",
      "           'the client’s expectations were met. The project was eventually '\n",
      "           'successfully completed and this was seen as a testament to my '\n",
      "           'leadership and decision-making abilities.',\n",
      " 'text': 'Below is an instruction that describes a task. Write a response that '\n",
      "         'appropriately completes the request.\\n'\n",
      "         '\\n'\n",
      "         '### Instruction:\\n'\n",
      "         'Describe a time when you had to make a difficult decision.\\n'\n",
      "         '\\n'\n",
      "         '### Response:\\n'\n",
      "         'I had to make a difficult decision when I was working as a project '\n",
      "         'manager at a construction company. I was in charge of a project that '\n",
      "         'needed to be completed by a certain date in order to meet the '\n",
      "         'client’s expectations. However, due to unexpected delays, we were '\n",
      "         'not able to meet the deadline and so I had to make a difficult '\n",
      "         'decision. I decided to extend the deadline, but I had to stretch the '\n",
      "         'team’s resources even further and increase the budget. Although it '\n",
      "         'was a risky decision, I ultimately decided to go ahead with it to '\n",
      "         'ensure that the project was completed on time and that the client’s '\n",
      "         'expectations were met. The project was eventually successfully '\n",
      "         'completed and this was seen as a testament to my leadership and '\n",
      "         'decision-making abilities.'}\n"
     ]
    }
   ],
   "source": [
    "m = 5\n",
    "top_m = itertools.islice(instruction_tuned_dataset, m)\n",
    "print(\"Instruction tuned dataset...\")\n",
    "for x in top_m:\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89a47a7b-8c51-4c54-b82d-82f603c23271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#two prompt templates\n",
    "\n",
    "#1. with input\n",
    "prompt_template_with_input = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
    "Write response that completes the request as per the instruction.\n",
    "###Instruction:\n",
    "{instruction}\n",
    "\n",
    "###Input:\n",
    "{input}\n",
    "\n",
    "###Response:\"\"\"\n",
    "\n",
    "#without input\n",
    "\n",
    "prompt_template_without_input=\"\"\"Below is an instruction that describes a task.\n",
    "Write response that completes the request as per the instruction.\n",
    "###Instruction:\n",
    "{instruction}\n",
    "\n",
    "###Response:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c9846a-2848-4db2-a6a6-b2570c01efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=10000\n",
    "top_m = itertools.islice(instruction_tuned_dataset, m)\n",
    "processed_data = []\n",
    "for j in top_m:\n",
    "    #without input\n",
    "    if not j['input']:         \n",
    "        processed_prompt = prompt_template_without_input.format(instruction=j['instruction'])\n",
    "    #with input\n",
    "    else:\n",
    "        processed_prompt = prompt_template_with_input.format(instruction=j['instruction'], input=j['input'])\n",
    "    processed_data.append({'input':processed_prompt, 'output':j['output']})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ae7c22-faa3-4feb-ab22-1afdc348f841",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(processed_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c685bd7a-0b0c-4d0a-8adb-f4a6fd73477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data\n",
    "with jsonlines.open(f'alpaca_processed_10000.jsonl', 'w') as writer:\n",
    "    writer.write_all(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd8d1b5-d1cc-42bf-9088-f23f87efd7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from huggingface \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18f26dd8-b82d-4fc8-bcbf-eedeabbc47af",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_instruct_model = BasicModelRunner('meta-llama/Llama-2-7b-hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243fe144-fb89-4ef1-aaf2-bf418196a3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_instruct_output = non_instruct_model(\"Tell me how to train my dog\")\n",
    "print(\"Non instruction-tuned model (Llama-2-7b-hf)'s output:\", non_instruct_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "914d2cb4-3388-495b-8fd9-0973731fb4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85ced505ea646b492af84da8b44abc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/166M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import TFAutoModelForCausalLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-70m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00828fe4-4b4c-4228-87a6-29b87743e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf26ddc7-d782-483a-810a-c2aa91708d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7e786a3-1dd0-4a26-b2c6-cfc66a4a39a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):\n",
    "    #tokenize\n",
    "    input_ids = tokenizer.encode(\n",
    "        text, return_tensors='pt',\n",
    "        truncation=True,\n",
    "        max_length=max_output_tokens\n",
    "    )\n",
    "\n",
    "    #generate\n",
    "    device = model.device\n",
    "    generated_tokens_with_prompt = model.generate(\n",
    "        input_ids = input_ids.to(device),\n",
    "        max_length = max_output_tokens\n",
    "    )\n",
    "    #decode\n",
    "    generated_text_with_prompt = tokenizer.batch_decode(\n",
    "        generated_tokens_with_prompt, \n",
    "        skip_special_tokens=True\n",
    "        )\n",
    "    #strip the prompt\n",
    "    generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
    "\n",
    "    return generated_text_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db2367d6-ce5a-4c15-844e-a99ad05e1cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-70m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed379855-07da-49fb-a183-76142bf82d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "question='Can Lamini generate technical documentation or user manuals for software projects?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91672dc8-0b25-40c5-adad-942254ccf0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "result = inference(question, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3202173c-cc4d-497b-8959-532cc6d2feed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n'\n",
      " '\\n'\n",
      " 'I have a question about the following:\\n'\n",
      " '\\n'\n",
      " 'How do I get the correct documentation to work?\\n'\n",
      " '\\n'\n",
      " 'A:\\n'\n",
      " '\\n'\n",
      " 'I think you need to use the following code:\\n'\n",
      " '\\n'\n",
      " 'A:\\n'\n",
      " '\\n'\n",
      " 'You can use the following code to get the correct documentation.\\n'\n",
      " '\\n'\n",
      " 'A:\\n'\n",
      " '\\n'\n",
      " 'You can use the following code to get the correct documentation.\\n'\n",
      " '\\n'\n",
      " 'A:\\n'\n",
      " '\\n'\n",
      " 'You can use the following')\n"
     ]
    }
   ],
   "source": [
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88dd1b3e-2d7a-4b3a-b571-5fab74a5f025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706504b844a74971b92da9078a1b286b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/717 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29a3dfc5a864ecdb8dae90f4cdcb62e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/282M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8486f85e094247b35ce524563f940e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "instruction_finetuned_model = AutoModelForCausalLM.from_pretrained(\"lamini/lamini_docs_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cf58b6f-bc30-4dfa-99ce-6f532e7c8269",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Yes, Lamini can generate technical documentation or user manuals for '\n",
      " 'software projects. This can be achieved by providing a prompt for a specific '\n",
      " 'technical question or question to the LLM Engine, or by providing a prompt '\n",
      " 'for a specific technical question or question. Additionally, Lamini can be '\n",
      " 'trained on specific technical questions or questions to help users '\n",
      " 'understand the process and provide feedback to the LLM Engine. Additionally, '\n",
      " 'Lamini')\n"
     ]
    }
   ],
   "source": [
    "pprint(inference(question, instruction_finetuned_model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e44592-94de-41e7-a05d-375110d8a293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe3998b-3203-46d1-bd6e-a3921e001905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b75f559-7314-4fb8-b681-1041a0072222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa8853c-29df-4730-98ee-ff3fd8098011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70877d6-ae7b-4f37-9168-71be6f003d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbfd870-bb8a-4b68-a216-ceee9cfda54a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc6823f-3ee9-43bd-80b5-6eccf3796735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60af030f-e891-4d84-8a44-aa0aeb27017b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37fa1bf-8954-40c1-be97-808534391d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e97c6f-5a78-4977-ad63-b135fb779a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937c513c-5291-4a26-8641-2d7ea4358eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b3ffae-0b8e-4ccc-967a-bbbe99169c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc113509-6abd-474d-bc1c-30069f5d784d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52416eab-85a5-48dd-82bf-7076f1b9d3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fcc1a7-6235-4188-90a2-0ab195df257e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20e3b57-0395-4205-aebb-5e0f840ad539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996a4eb2-657d-4152-903c-f528f6460060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bb3cfe-e968-495a-9592-541b39925ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b88638-dcc4-4af7-adc2-cdcb36867ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67aa245-0b28-4ed2-955e-0ad123b3daeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627fcfbf-d0ed-49e1-8f45-d4ed7a45f64a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721f16a9-02a4-41f9-a3f7-4c42b449fe97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d281bc9-faf1-479f-83a6-156c1a3b7118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b32bfe3-5f1f-4708-8301-a5afeb6f63c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ceea5f-7246-4fa5-9062-b4f757fd73b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980a1071-5fac-4323-9e35-b8443d6596fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eb7000-8f55-45a2-ae35-c3e0dd8b5883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f252b7-bc14-4629-9a29-a04412a70805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f9f34d-5e6b-4a68-927f-dff3cb629cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ba41d2-b23d-4b83-9661-92df3be86605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644d8562-7717-4a9e-b933-409824cab174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ddd30b-0889-414d-a24a-44043e74647b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca18d02-d9bd-4c8d-a92c-e30317248f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4818e7eb-ebfc-4c81-9a2a-ab3d4b9c73d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36534f0c-abb8-4175-ada1-0a014ddf8c34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d978d3e-887f-4e41-a972-f64a799e83b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecfb22e-5f63-4e9a-b1d4-507ae2d5b040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "botenv",
   "language": "python",
   "name": "botenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
